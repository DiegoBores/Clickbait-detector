{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoBores/Clickbait-detector/blob/main/DetectorClickbait.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUS1JjGyjGdo"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "17cdrczLIpip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cba9da-c189-48cb-e132-fd9ec60cb362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k7WXglbkSODr"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IaE1HGdwH-dP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "from official.nlp import optimization #for  AdamW optimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import cross_val_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBKGY4VUjWSs"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h38KU5_NJJ5n"
      },
      "outputs": [],
      "source": [
        "#Obtenemos las URL y los path relativos correspondientes a los dataset de entrenamiento y de test\n",
        "TRAIN_DATA_URL = \"https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_train.csv\"#URL del conjunto de entrenamiento\n",
        "TEST_DATA_URL = \"https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_test.csv\"#URL del conjunto de test\n",
        "\n",
        "#Descargamos los datasets\n",
        "train_file_path = tf.keras.utils.get_file(\"webis_train.csv\", TRAIN_DATA_URL,\n",
        "                                          cache_dir='.', cache_subdir='datasets')\n",
        "test_file_path = tf.keras.utils.get_file('webis_test.csv', TEST_DATA_URL,\n",
        "                                         cache_dir='.', cache_subdir='datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tqucWJIjImC2"
      },
      "outputs": [],
      "source": [
        "#Leemos los csv y los almacenamos en sendos dataframes de pandas\n",
        "train_df = pd.read_csv(train_file_path) \n",
        "test_df = pd.read_csv(test_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FP96L5pGJuRS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c4262797-3288-4679-f68f-3353b14a60ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                               postMedia  \\\n",
              "4399         4399                                      []   \n",
              "5288         5288  ['media/photo_820407651452338176.jpg']   \n",
              "18488       18488                                      []   \n",
              "31             31  ['media/photo_857416781736157184.jpg']   \n",
              "8967         8967  ['media/photo_827573620830507012.jpg']   \n",
              "\n",
              "                                                postText                  id  \\\n",
              "4399   Woman pulled alive from the River Thames besid...  844599361149571072   \n",
              "5288   Brain cancer survivor running 7 marathons on 7...  820407654275223552   \n",
              "18488  #Bengaluru #police is being #accused of refusi...  832658468708323328   \n",
              "31     Congresswomen meet to discuss missing women of...  857416784953188352   \n",
              "8967   Some patients are testing psychedelic drug the...  827573622982197248   \n",
              "\n",
              "                                          targetCaptions  \\\n",
              "4399   ['The woman receives treatment after being pul...   \n",
              "5288                                                  []   \n",
              "18488                                ['Flame', 'Police']   \n",
              "31     ['PHOTO: Exterior view of the U.S. Capitol bui...   \n",
              "8967   ['Some doctors and patients are testing psyche...   \n",
              "\n",
              "                                        targetParagraphs  \\\n",
              "4399   ['A woman has been pulled alive from the River...   \n",
              "5288   ['January 14, 2017, 2:31 PM| Some people spend...   \n",
              "18488  ['In a shocking case of indifference and \\xa0r...   \n",
              "31     [\"Following last month's spike in social media...   \n",
              "8967   ['SAN FRANCISCO — In the 1950s and 60s, psyche...   \n",
              "\n",
              "                                             targetTitle  \\\n",
              "4399   Woman pulled alive from River Thames after Wes...   \n",
              "5288   Brain cancer survivor running 7 marathons on 7...   \n",
              "18488  Five-Year-Old Bengaluru Girl Burnt Alive After...   \n",
              "31     Congresswomen meet to discuss missing women of...   \n",
              "8967   Some patients try psychedelic drug therapy for...   \n",
              "\n",
              "                        postTimestamp  \\\n",
              "4399   Wed Mar 22 17:19:14 +0000 2017   \n",
              "5288   Sat Jan 14 23:10:01 +0000 2017   \n",
              "18488  Fri Feb 17 18:30:23 +0000 2017   \n",
              "31     Thu Apr 27 02:11:06 +0000 2017   \n",
              "8967   Fri Feb 03 17:45:01 +0000 2017   \n",
              "\n",
              "                                          targetKeywords  \\\n",
              "4399   Parliament shooting,Terrorism,Westminster,Stan...   \n",
              "5288   Brain cancer survivor running 7 marathons on 7...   \n",
              "18488  Bengaluru Police, Child Rape, KSCPCR, Bannergh...   \n",
              "31     congresswomen, D.C., capitol hill, missing gir...   \n",
              "8967   psilobycin, Dr. Charles Grob, Johns Hopkins, m...   \n",
              "\n",
              "                                       targetDescription  \\\n",
              "4399   A woman has been pulled alive from the River T...   \n",
              "5288   Some people spend months training for one mara...   \n",
              "18488  Five Year-Old Bengaluru Girl Burnt Alive After...   \n",
              "31     Congresswomen and law enforcement representati...   \n",
              "8967   Some doctors are testing the use of drugs like...   \n",
              "\n",
              "                                          truthJudgments  truthMean  \\\n",
              "4399                           [1.0, 0.0, 0.0, 0.0, 0.0]   0.200000   \n",
              "5288                           [1.0, 0.0, 0.0, 0.0, 0.0]   0.200000   \n",
              "18488          [0.0, 0.0, 0.0, 0.0, 0.33333333330000003]   0.066667   \n",
              "31                             [1.0, 0.0, 0.0, 0.0, 0.0]   0.200000   \n",
              "8967   [0.33333333330000003, 0.6666666666000001, 0.33...   0.266667   \n",
              "\n",
              "         truthClass  truthMedian  truthMode  \n",
              "4399   no-clickbait     0.000000   0.000000  \n",
              "5288   no-clickbait     0.000000   0.000000  \n",
              "18488  no-clickbait     0.000000   0.000000  \n",
              "31     no-clickbait     0.000000   0.000000  \n",
              "8967   no-clickbait     0.333333   0.333333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a3bf5a4-8cec-4f3f-bbc3-d180c7e0c6cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>postMedia</th>\n",
              "      <th>postText</th>\n",
              "      <th>id</th>\n",
              "      <th>targetCaptions</th>\n",
              "      <th>targetParagraphs</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>postTimestamp</th>\n",
              "      <th>targetKeywords</th>\n",
              "      <th>targetDescription</th>\n",
              "      <th>truthJudgments</th>\n",
              "      <th>truthMean</th>\n",
              "      <th>truthClass</th>\n",
              "      <th>truthMedian</th>\n",
              "      <th>truthMode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4399</th>\n",
              "      <td>4399</td>\n",
              "      <td>[]</td>\n",
              "      <td>Woman pulled alive from the River Thames besid...</td>\n",
              "      <td>844599361149571072</td>\n",
              "      <td>['The woman receives treatment after being pul...</td>\n",
              "      <td>['A woman has been pulled alive from the River...</td>\n",
              "      <td>Woman pulled alive from River Thames after Wes...</td>\n",
              "      <td>Wed Mar 22 17:19:14 +0000 2017</td>\n",
              "      <td>Parliament shooting,Terrorism,Westminster,Stan...</td>\n",
              "      <td>A woman has been pulled alive from the River T...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5288</th>\n",
              "      <td>5288</td>\n",
              "      <td>['media/photo_820407651452338176.jpg']</td>\n",
              "      <td>Brain cancer survivor running 7 marathons on 7...</td>\n",
              "      <td>820407654275223552</td>\n",
              "      <td>[]</td>\n",
              "      <td>['January 14, 2017, 2:31 PM| Some people spend...</td>\n",
              "      <td>Brain cancer survivor running 7 marathons on 7...</td>\n",
              "      <td>Sat Jan 14 23:10:01 +0000 2017</td>\n",
              "      <td>Brain cancer survivor running 7 marathons on 7...</td>\n",
              "      <td>Some people spend months training for one mara...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18488</th>\n",
              "      <td>18488</td>\n",
              "      <td>[]</td>\n",
              "      <td>#Bengaluru #police is being #accused of refusi...</td>\n",
              "      <td>832658468708323328</td>\n",
              "      <td>['Flame', 'Police']</td>\n",
              "      <td>['In a shocking case of indifference and \\xa0r...</td>\n",
              "      <td>Five-Year-Old Bengaluru Girl Burnt Alive After...</td>\n",
              "      <td>Fri Feb 17 18:30:23 +0000 2017</td>\n",
              "      <td>Bengaluru Police, Child Rape, KSCPCR, Bannergh...</td>\n",
              "      <td>Five Year-Old Bengaluru Girl Burnt Alive After...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.33333333330000003]</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>['media/photo_857416781736157184.jpg']</td>\n",
              "      <td>Congresswomen meet to discuss missing women of...</td>\n",
              "      <td>857416784953188352</td>\n",
              "      <td>['PHOTO: Exterior view of the U.S. Capitol bui...</td>\n",
              "      <td>[\"Following last month's spike in social media...</td>\n",
              "      <td>Congresswomen meet to discuss missing women of...</td>\n",
              "      <td>Thu Apr 27 02:11:06 +0000 2017</td>\n",
              "      <td>congresswomen, D.C., capitol hill, missing gir...</td>\n",
              "      <td>Congresswomen and law enforcement representati...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8967</th>\n",
              "      <td>8967</td>\n",
              "      <td>['media/photo_827573620830507012.jpg']</td>\n",
              "      <td>Some patients are testing psychedelic drug the...</td>\n",
              "      <td>827573622982197248</td>\n",
              "      <td>['Some doctors and patients are testing psyche...</td>\n",
              "      <td>['SAN FRANCISCO — In the 1950s and 60s, psyche...</td>\n",
              "      <td>Some patients try psychedelic drug therapy for...</td>\n",
              "      <td>Fri Feb 03 17:45:01 +0000 2017</td>\n",
              "      <td>psilobycin, Dr. Charles Grob, Johns Hopkins, m...</td>\n",
              "      <td>Some doctors are testing the use of drugs like...</td>\n",
              "      <td>[0.33333333330000003, 0.6666666666000001, 0.33...</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3bf5a4-8cec-4f3f-bbc3-d180c7e0c6cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a3bf5a4-8cec-4f3f-bbc3-d180c7e0c6cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a3bf5a4-8cec-4f3f-bbc3-d180c7e0c6cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Podemos ver una muestra del dataset de entrenamiento\n",
        "train_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rmp6Bqs7Kd"
      },
      "source": [
        "Descripcion del dataset de entrenamiento (campos a utilizar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTU_EQ6StTeC"
      },
      "source": [
        "Comprobamos que no haya valores null en los campos que nos interesan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yN1Rj5IRgQjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77d3d31-42fa-403c-b21b-0da4a13adfcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0           False\n",
              "postMedia            False\n",
              "postText              True\n",
              "id                   False\n",
              "targetCaptions       False\n",
              "targetParagraphs     False\n",
              "targetTitle          False\n",
              "postTimestamp        False\n",
              "targetKeywords        True\n",
              "targetDescription     True\n",
              "truthJudgments       False\n",
              "truthMean            False\n",
              "truthClass           False\n",
              "truthMedian          False\n",
              "truthMode            False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dxz8HNwiwOQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84acb9b5-6811-4e16-e0a6-0de5d3f500b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0           False\n",
              "id                   False\n",
              "postMedia            False\n",
              "targetCaptions       False\n",
              "postText              True\n",
              "postTimestamp        False\n",
              "targetTitle          False\n",
              "targetDescription     True\n",
              "targetKeywords        True\n",
              "targetParagraphs     False\n",
              "truthJudgments       False\n",
              "truthClass           False\n",
              "truthMedian          False\n",
              "truthMode            False\n",
              "truthMean            False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_df.isnull().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJddFGY5tcsF"
      },
      "source": [
        "Puesto que la columna de texto que nos interesa tiene valores Null, debemos eliminarlos para que no nos de problemas a la hora de entrenar el modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8wMh1rLmtbyN"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.dropna(how='any',subset=['postText', 'truthClass'], axis=0)\n",
        "test_df = test_df.dropna(how='any',subset=['postText', 'truthClass'], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RhP9XZqiKMYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f696d32c-1c42-41aa-89ad-0956255b0774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#Cambiamos los valores de 'truthClass' a valores 1 o 0 en funcion de si es un clickbait o no\n",
        "#En el conjunto de entrenamiento\n",
        "train_df['truthClass'] = train_df['truthClass'].apply(lambda x: 1 if x=='clickbait' else 0 )\n",
        "train_df.rename(columns={'truthClass':'target'}, inplace=True)\n",
        "#En el conjunto de test\n",
        "test_df['truthClass'] = test_df['truthClass'].apply(lambda x: 1 if x=='clickbait' else 0 )\n",
        "test_df.rename(columns={'truthClass':'target'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_AbqmgYJ0S_",
        "outputId": "00142774-9f09-4cd9-e463-e92887dcc803"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14768\n",
              "1     4716\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#contamos  cuantos ejemplos del dataset de entrenamiento contienen un clickbait y cuantos no\n",
        "train_df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZPv9DR-KA_-"
      },
      "source": [
        "un 33% de los valores son clickbait. Implica un desbalanceo entre las clases que podría conducir a un alto sesgo durante el entrenamiento del modelo. Para evitar esto vamos a intentar balancear los datos, eliminando elementos que contengan 'no-clickbait' hasta que igualen a los de 'clikbait'. \n",
        "Además, por motivos de limitaciones computacionales y de tiempo, el fine-tunning será más rápido al disminuir el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clickbait = train_df[train_df['target']==1]\n",
        "df_noclickbait = train_df[train_df['target']==0]\n",
        "\n",
        "df_noclickbait_downsampled=df_noclickbait.sample(df_clickbait.shape[0])\n",
        "\n",
        "train_df = pd.concat([df_noclickbait_downsampled, df_clickbait])\n",
        "train_df=train_df.sample(frac=1)"
      ],
      "metadata": {
        "id": "0_Aj1cxN5GwO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhowUV4p6QA6",
        "outputId": "5ef7203e-228c-4a16-ae6c-7d36e4e21d46"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4716\n",
              "0    4716\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eQBmNB3e6cod"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fcfShkCY631Z",
        "outputId": "19fa505c-1161-4e66-ced9-2c58dd4921b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                               postMedia  \\\n",
              "10935       10935  ['media/photo_826028891798196228.jpg']   \n",
              "5526         5526  ['media/photo_813617413665255424.jpg']   \n",
              "8619         8619  ['media/photo_836208042022596609.jpg']   \n",
              "16085       16085                                      []   \n",
              "7573         7573  ['media/photo_811317767441879041.jpg']   \n",
              "\n",
              "                                                postText                  id  \\\n",
              "10935                        The world's 20 best beaches  826056122708680704   \n",
              "5526                     Biggest celebrity feuds of 2016  813617415561052160   \n",
              "8619   #Tennis Australia 🎾 to set up help line for al...  836208098167529472   \n",
              "16085              The Final Four is set.\\n\\nWho ya got?  846346154115825664   \n",
              "7573   Bring Me The Horizon's @olobersyko created a \"...  811317770042408960   \n",
              "\n",
              "                                          targetCaptions  \\\n",
              "10935  ['Seychelles', \"A broad stretch of sand is the...   \n",
              "5526   ['<p>Tempers were flying high on the set of th...   \n",
              "8619   ['BXJ mother', 'Tennis organisation defends ho...   \n",
              "16085                                                 []   \n",
              "7573   ['Joseph Okpako/WireImage Oliver Sykes of Brin...   \n",
              "\n",
              "                                        targetParagraphs  \\\n",
              "10935  ['30 Jan 2017', 'A broad stretch of sand is th...   \n",
              "5526   ['More', 'Tempers were flying high on the set ...   \n",
              "8619   ['Tennis Australia is hoping to set up a Crime...   \n",
              "16085  [\"The Final Four of the 2017 NCAA tournament i...   \n",
              "7573   ['Bring Me The Horizon frontman\\xa0Oli Sykes i...   \n",
              "\n",
              "                                             targetTitle  \\\n",
              "10935     Beach holidays The world's 20 greatest beaches   \n",
              "5526                     Biggest Celebrity Feuds of 2016   \n",
              "8619   Tennis Australia to set up help line for alleg...   \n",
              "16085  Vote: Four burning questions heading into Fina...   \n",
              "7573   Bring Me The Horizon's Oli Sykes Created a 'St...   \n",
              "\n",
              "                        postTimestamp  \\\n",
              "10935  Mon Jan 30 13:15:01 +0000 2017   \n",
              "5526   Tue Dec 27 05:28:02 +0000 2016   \n",
              "8619   Mon Feb 27 13:35:21 +0000 2017   \n",
              "16085  Mon Mar 27 13:00:22 +0000 2017   \n",
              "7573   Tue Dec 20 21:10:04 +0000 2016   \n",
              "\n",
              "                                          targetKeywords  \\\n",
              "10935                     travel,beaches,Family holidays   \n",
              "5526                                                 NaN   \n",
              "8619   tennis australia, noel callaghan, sexual abuse...   \n",
              "16085  gonzaga bulldogs, gonzaga, zags, final four, m...   \n",
              "7573                                                 NaN   \n",
              "\n",
              "                                       targetDescription  \\\n",
              "10935                                                NaN   \n",
              "5526   With all the horrible things going on in the w...   \n",
              "8619   Tennis Australia is hoping to set up a Crimest...   \n",
              "16085  The Final Four is set. Here are four important...   \n",
              "7573   Bring Me The Horizon frontman Oli Sykes releas...   \n",
              "\n",
              "                                          truthJudgments  truthMean  target  \\\n",
              "10935                          [1.0, 1.0, 1.0, 1.0, 1.0]   1.000000       1   \n",
              "5526   [0.6666666666000001, 0.6666666666000001, 1.0, ...   0.866667       1   \n",
              "8619                           [0.0, 0.0, 0.0, 0.0, 0.0]   0.000000       0   \n",
              "16085  [0.33333333330000003, 1.0, 0.6666666666000001,...   0.733333       1   \n",
              "7573   [0.0, 0.33333333330000003, 0.33333333330000003...   0.200000       0   \n",
              "\n",
              "       truthMedian  truthMode  \n",
              "10935     1.000000   1.000000  \n",
              "5526      1.000000   1.000000  \n",
              "8619      0.000000   0.000000  \n",
              "16085     0.666667   0.666667  \n",
              "7573      0.333333   0.333333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa0f7c37-4c99-4520-a535-10c1ca6c331a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>postMedia</th>\n",
              "      <th>postText</th>\n",
              "      <th>id</th>\n",
              "      <th>targetCaptions</th>\n",
              "      <th>targetParagraphs</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>postTimestamp</th>\n",
              "      <th>targetKeywords</th>\n",
              "      <th>targetDescription</th>\n",
              "      <th>truthJudgments</th>\n",
              "      <th>truthMean</th>\n",
              "      <th>target</th>\n",
              "      <th>truthMedian</th>\n",
              "      <th>truthMode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10935</th>\n",
              "      <td>10935</td>\n",
              "      <td>['media/photo_826028891798196228.jpg']</td>\n",
              "      <td>The world's 20 best beaches</td>\n",
              "      <td>826056122708680704</td>\n",
              "      <td>['Seychelles', \"A broad stretch of sand is the...</td>\n",
              "      <td>['30 Jan 2017', 'A broad stretch of sand is th...</td>\n",
              "      <td>Beach holidays The world's 20 greatest beaches</td>\n",
              "      <td>Mon Jan 30 13:15:01 +0000 2017</td>\n",
              "      <td>travel,beaches,Family holidays</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5526</th>\n",
              "      <td>5526</td>\n",
              "      <td>['media/photo_813617413665255424.jpg']</td>\n",
              "      <td>Biggest celebrity feuds of 2016</td>\n",
              "      <td>813617415561052160</td>\n",
              "      <td>['&lt;p&gt;Tempers were flying high on the set of th...</td>\n",
              "      <td>['More', 'Tempers were flying high on the set ...</td>\n",
              "      <td>Biggest Celebrity Feuds of 2016</td>\n",
              "      <td>Tue Dec 27 05:28:02 +0000 2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>With all the horrible things going on in the w...</td>\n",
              "      <td>[0.6666666666000001, 0.6666666666000001, 1.0, ...</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8619</th>\n",
              "      <td>8619</td>\n",
              "      <td>['media/photo_836208042022596609.jpg']</td>\n",
              "      <td>#Tennis Australia 🎾 to set up help line for al...</td>\n",
              "      <td>836208098167529472</td>\n",
              "      <td>['BXJ mother', 'Tennis organisation defends ho...</td>\n",
              "      <td>['Tennis Australia is hoping to set up a Crime...</td>\n",
              "      <td>Tennis Australia to set up help line for alleg...</td>\n",
              "      <td>Mon Feb 27 13:35:21 +0000 2017</td>\n",
              "      <td>tennis australia, noel callaghan, sexual abuse...</td>\n",
              "      <td>Tennis Australia is hoping to set up a Crimest...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16085</th>\n",
              "      <td>16085</td>\n",
              "      <td>[]</td>\n",
              "      <td>The Final Four is set.\\n\\nWho ya got?</td>\n",
              "      <td>846346154115825664</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"The Final Four of the 2017 NCAA tournament i...</td>\n",
              "      <td>Vote: Four burning questions heading into Fina...</td>\n",
              "      <td>Mon Mar 27 13:00:22 +0000 2017</td>\n",
              "      <td>gonzaga bulldogs, gonzaga, zags, final four, m...</td>\n",
              "      <td>The Final Four is set. Here are four important...</td>\n",
              "      <td>[0.33333333330000003, 1.0, 0.6666666666000001,...</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7573</th>\n",
              "      <td>7573</td>\n",
              "      <td>['media/photo_811317767441879041.jpg']</td>\n",
              "      <td>Bring Me The Horizon's @olobersyko created a \"...</td>\n",
              "      <td>811317770042408960</td>\n",
              "      <td>['Joseph Okpako/WireImage Oliver Sykes of Brin...</td>\n",
              "      <td>['Bring Me The Horizon frontman\\xa0Oli Sykes i...</td>\n",
              "      <td>Bring Me The Horizon's Oli Sykes Created a 'St...</td>\n",
              "      <td>Tue Dec 20 21:10:04 +0000 2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bring Me The Horizon frontman Oli Sykes releas...</td>\n",
              "      <td>[0.0, 0.33333333330000003, 0.33333333330000003...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa0f7c37-4c99-4520-a535-10c1ca6c331a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa0f7c37-4c99-4520-a535-10c1ca6c331a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa0f7c37-4c99-4520-a535-10c1ca6c331a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgIOh4sCIBHj"
      },
      "source": [
        "Dividimos el dataset en train y validation en una relacion 80/20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bhbG9voVQpSS"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_df['postText'],train_df['target'], train_size=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ua7lSCjuCcn"
      },
      "source": [
        "Vamos a extraer del conjunto de test las columnas que nos interesan, y en el mismo formato que los de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U6vsQtFkuKwS"
      },
      "outputs": [],
      "source": [
        "X_test = test_df['postText']\n",
        "y_test = test_df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRXI-WhYjcIt"
      },
      "source": [
        "# Modelos a utilizar:\n",
        "\n",
        "Utilizaremos tres modelos:\n",
        "\n",
        "\n",
        "*   Un modelo BERT sencillo, llamado Small BERT\n",
        "*   ELECTRA base\n",
        "*   Un baseline sencillo para comparar los resultados obtenidos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> # Small BERT\n",
        "\n",
        "Se trata de un modelo basado en BERT original, pero con menos bloques Transformer y/o más pequeños.\n",
        "Utilizaremos el modelo SmallBERT con la configuración\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpUeVeYlRQg1"
      },
      "outputs": [],
      "source": [
        "smallBERT_preprocess_handle = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "smallBERT_encoder_handle = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1', trainable=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxv3m_XiSg_w"
      },
      "source": [
        "> > > # Modelo de preprocesado\n",
        "\n",
        "\n",
        "Las entradas de texto deben ser transformadas a tokens numericoas y agrupados en tensores antes de ser entradas de BERT. TensorFlow Hub facilita un modelo de preprocesamiento para cada modelo BERT discutido antes, por lo que no es necesario correr codigo de Python especifico fura del modelo de TensorFlow para preprocesar el texto.\n",
        "\n",
        "El modelo de preoprocesamiento indicado en la documentacion del modelo BERT.\n",
        "\n",
        "Del preprocesado hay tres salidas principales, que serán las utilizadas por el modelo BERT:\n",
        "input_words_id, input_mask e input_type_ids\n",
        "\n",
        "\n",
        "> > > # Modelo BERT\n",
        "\n",
        "Los modelos BERT devuelven un map con 3 keys importantes: pooled_output, sequence_output y encoder_outputs:\n",
        "\n",
        "pooled_output representa cada frase de entrada como un conjunto. Las dimensiones son [batch_size, H].\n",
        "sequence_output representa cada token de entrada en el contexto. Las dimensiones son [batch_size, seq_length, H].\n",
        "encoder_outputs son las activaciones intermedias de los L bloques Transformer. outputs[\"encoder_outputs\"][i] es un tensor con dimensiones[batch_size, seq_length, 1024] con las salidas del i-esimo bloque Transformer, para 0<=i<L. El ultimo valor de esta lista es igual a sequence_output.\n",
        "Para el fine-tunning se utiliza el array pooled_output\n",
        "\n",
        "> > > # Definicion del modelo\n",
        "\n",
        "El modelo utilizado es uno sencillo, con el preprocesado, el modelo Small BERT, una capa Dropout y una capa Dense.\n",
        "\n",
        "La capa Dropout se utiliza para evitar que el modelo se sebreajuste. La entrada de esta capa será la salida pooled_outputs del modelo BERT.\n",
        "La capa Dense tiene solo una neurona. Utilizamos una funcion de activacion sigmoid, dado que los valores de salida están entre 0 y 1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj_SvrRwSmpb"
      },
      "outputs": [],
      "source": [
        "#Crearemos una función que construya el modelo a apartir de las url del modulo de preprocesado y del modulo BERT empleado\n",
        "def build_classifier_model(preprocess_handle, encoder_handle):\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(preprocess_handle, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(encoder_handle, trainable = True, name='encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net=outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJYTcD3GpGwR"
      },
      "source": [
        "Vamos a echar un vistazo al esquema del modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mevMiGNLpC-f"
      },
      "outputs": [],
      "source": [
        "smallBERT_classifier_model = build_classifier_model(smallBERT_preprocess_handle , smallBERT_encoder_handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifpxxib1pfJO"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(smallBERT_classifier_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEy1NEXJpkX7"
      },
      "outputs": [],
      "source": [
        "smallBERT_classifier_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOZau3f4UEuE"
      },
      "source": [
        "> > > # Función de pérdidas, optimizador y metricas\n",
        "\n",
        "Dado que se trata de un problema de clasificacion binaria, y la salida del modelo es una probabilidad (es una capa con una única unidad),utilizaremos la funcion de costes losses.BinaryCrossentropy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtvCbsK7qnq0"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w31UDpO2qz-E"
      },
      "source": [
        "Metrics will be used to check the model performance so that we can know how we trained our model. We set the BinaryAccuracy(name='accuracy') which will be used to calculate the accuracy score of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3YjM6UKq0tc"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "           tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "           tf.keras.metrics.Precision(name='precision'),\n",
        "           tf.keras.metrics.Recall(name='recall')\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypjlbzdeq4rD"
      },
      "source": [
        "Para el fine-tunning utilizaremos el mismo con el que se entrenó originalmente BERT: \"Adaptative Moments\" (Adam). Este optimizador minimiza la perdida de la prediccion y emplea regularización mediante disminucion de pesos (no emplea momentos), que se conoce como AdamW.\n",
        "\n",
        "Para la tasa de aprendizaje (init_lr) emplearemos el mismo esquema que en el pre-entrenamiento de BERT: disminucion linear de una tasa inicial, prefijada con una fase de calentamiento linear sobre el 10% de los pasos de entrenamiento(num_warmup_steps). De acuerdo con el paper de BERT, la tasa de aprendizaje inicial debe ser más pequeña para el fine-tunning( mejor de 5e-5, 3e-5, 2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz5t3kY_q-Nb"
      },
      "outputs": [],
      "source": [
        "# epochs = 1 #numero de epochs inicialmente 1\n",
        "# steps_per_epoch = tf.data.experimental.cardinality((X_train, y_train)).numpy()\n",
        "# num_train_steps = steps_per_epoch * epochs #Numero de pasos de entrenamiento\n",
        "# num_warmup_steps = int(0.1*num_train_steps) #Numero de pasos de calentamiento\n",
        "\n",
        "# #Tasa de aprendizaje inicial\n",
        "# init_lr = 3e-5\n",
        "# optimizer = optimization.create_optimizer(init_lr = init_lr,\n",
        "#                                           num_train_steps=num_train_steps,\n",
        "#                                           num_warmup_steps=num_warmup_steps,\n",
        "#                                           optimizer_type='adamw')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-97S-8h_rgxA"
      },
      "source": [
        "> > > # Compilando el modelo y fine-tunning\n",
        "\n",
        "A continuación, compilamos el modelo definido anteriormente. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XCWztPgrgFI"
      },
      "outputs": [],
      "source": [
        "smallBERT_classifier_model.compile(optimizer= 'adam',\n",
        "                                   loss=loss,\n",
        "                                   metrics = METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxFa_uoQr3qr"
      },
      "source": [
        "Y realizamos el fine-tunning. Por limitaciones computacionales y de timepo, reduciremos el numero de epochs a 4, si bien este numero debería ser bastante mayor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy8d70QVr7fd"
      },
      "outputs": [],
      "source": [
        "smallBERT_history = smallBERT_classifier_model.fit(X_train,y_train, \n",
        "                                                   validation_data=(X_val, y_val), \n",
        "                                                   epochs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis de accuracy en train y en val. Relacion con overfitting, etc. "
      ],
      "metadata": {
        "id": "HKa08dlqTbJz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrVT1r7_sK3X"
      },
      "source": [
        "> > > # Evaluación del modelo\n",
        "\n",
        "Vamos a ver el rendimiento del modelo. Se devuelven dos valores: Loss(un numero que representa el error. Menores valores son mejores) y la precision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Qyepj6lWsRGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab869a5f-2306-49fe-ec7c-ff81a78b3ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 24s 8s/step - loss: 0.6501 - accuracy: 0.6800 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "smallBERT_metrics= smallBERT_classifier_model.evaluate(X_test[0:50], y_test[0:50])\n",
        "\n",
        "y_predicted = smallBERT_classifier_model.predict(X_test[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(smallBERT_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B7UBmJaeVwi",
        "outputId": "41e9f232-83e6-4c76-c4d4-bcf956d8a880"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6501409411430359, 0.6800000071525574, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcXGOSG-Y8az",
        "outputId": "e4ba1be0-e3a6-4852-b01c-bcde9b8f85eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1287171 ]\n",
            " [0.0844087 ]\n",
            " [0.63812006]\n",
            " [0.10491264]\n",
            " [0.4223712 ]\n",
            " [0.54527897]\n",
            " [0.18271327]\n",
            " [0.6933144 ]\n",
            " [0.17541182]\n",
            " [0.10552812]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Ck-M8RZAP4",
        "outputId": "70f161eb-7818-4723-ddf6-391335a0609f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    0\n",
            "4    0\n",
            "5    0\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    0\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LluXBu9vSs3"
      },
      "source": [
        "Podemos realizar una representacion de la evolucion de las perdidas y de la precision con el tiempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO_gU9xLvaCZ"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "smallBERT_acc = history_dict['binary_accuracy']\n",
        "smallBERT_val_acc = history_dict['val_binary_accuracy']\n",
        "smallBERT_loss = history_dict['loss']\n",
        "smallBERT_val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) +1)\n",
        "fig = plt.figure(figsize = (10,6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, smallBERT_loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, smallBERT_val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, smallBERT_acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, smallBERT_val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usZ6mX9IvpT8"
      },
      "source": [
        "Por último vamos a exportar el modelo obtenido para utilizarlo mas adelante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQnqBxQ6vv6s"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'webis'\n",
        "saved_model_path = './{}_smallBERT'.format(dataset_name.replace('/', '_'))\n",
        "smallBERT_classifier_model.save(saved_model_path, include_optimizer = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> # ELECTRA\n",
        "\n",
        "Se trata de un modelo basado en BER, pero que ha sido pre-entrenado como un discriminador en una GAN(Generative Adversarial Network). Utilizamos el tamaño intermedio, base. Se encuentra disponible en TensorFlow Hub, de modo que podemos compararlo fácilmente con el resultado de Small BERT.\n",
        "\n",
        "> > > # Definicion del modelo\n",
        "\n",
        "Utilizamos el mismo modelo que en el caso de smallBERT, cambiando únicamente el modelo de codificador, que ahora será electra_base, y su preprocesador correspondiente. \n"
      ],
      "metadata": {
        "id": "BfNSfAm7F1KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electraBase_preprocess_url = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "electraBase_encoder_url = hub.KerasLayer('https://tfhub.dev/google/electra_base/2', trainable=True)"
      ],
      "metadata": {
        "id": "hsSBN7x-Hyl8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "electraBase_classifier_model = build_classifier_model(electraBase_preprocess_url , electraBase_encoder_url)"
      ],
      "metadata": {
        "id": "geJBnt_GIDsz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFZNnHYZPxvP"
      },
      "source": [
        "Vamos a echar un vistazo al esquema del modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEjv4V-TP31y"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(electraBase_classifier_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "kbVm3sCfP311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efd2d74-c6ae-4d25-c932-03318ac8a5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " encoder (KerasLayer)           {'encoder_outputs':  109482241   ['preprocessing[0][0]',          \n",
            "                                 [(None, 128, 768),               'preprocessing[0][1]',          \n",
            "                                 (None, 128, 768),                'preprocessing[0][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 768)          0           ['encoder[0][13]']               \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            769         ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "electraBase_classifier_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de pérdidas, las métricas de rendimiento y el optimizador serán los utilzados en el caso anterior. Por lo tanto, sólo nos queda compilar el modelo y realizar el fine-tunning:"
      ],
      "metadata": {
        "id": "FZ0KsXf3P9au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electraBase_classifier_model.compile(optimizer= 'adam',\n",
        "                                   loss=loss,\n",
        "                                   metrics = METRICS)"
      ],
      "metadata": {
        "id": "aI3hRwNMQRBF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "electra_history = electraBase_classifier_model.fit(X_train,y_train, validation_data=(X_val, y_val), epochs=1)"
      ],
      "metadata": {
        "id": "iV-XqPTgQULu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "d660841d-75dd-49b5-9934-a34a336485ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13/488 [..............................] - ETA: 7:27:41 - loss: 1.0447 - accuracy: 0.6851 - precision: 0.1818 - recall: 0.1348"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2acdd447cbde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melectra_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectraBase_classifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj7Oe6zmQgg9"
      },
      "source": [
        "> > > # Evaluación del modelo\n",
        "\n",
        "Vamos a ver el rendimiento del modelode manera idéntica al caso anterior.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "electra_loss, electra_accuracy = electraBase_classifier_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "hKXWhs7KQmZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y realizamos laas gráficas oportunas"
      ],
      "metadata": {
        "id": "N-BUfpopQo5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electra_history_dict = electra_history.history\n",
        "print(electra_history_dict.keys())\n",
        "\n",
        "electra_acc = electra_history_dict['binary_accuracy']\n",
        "electra_val_acc = electra_history_dict['val_binary_accuracy']\n",
        "electra_loss = electra_history_dict['loss']\n",
        "electra_val_loss = electra_history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) +1)\n",
        "fig = plt.figure(figsize = (10,6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, electra_loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, electra_val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, electra_acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, electra_val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "yDInf2blRDM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI1wsBWTRkVZ"
      },
      "source": [
        "Por último vamos a exportar el modelo obtenido para utilizarlo mas adelante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc0389qsRkVy"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'webis'\n",
        "saved_model_path = './{}_electraBase'.format(dataset_name.replace('/', '_'))\n",
        "electraBase_classifier_model.save(saved_model_path, include_optimizer = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> # Clasificador sencillo\n",
        "\n"
      ],
      "metadata": {
        "id": "a1B78ormF62D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DummyClassifier()\n",
        "scores = cross_val_score(clf, X_train, y_train)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std()*2))"
      ],
      "metadata": {
        "id": "CYeju7lzGpy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9305a0-aabd-4947-8733-7acc4c9ea977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy classifier score: 0.758 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DetectorClickbait",
      "provenance": [],
      "authorship_tag": "ABX9TyPNc7a/QMnbqnTOUDxjNukp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}